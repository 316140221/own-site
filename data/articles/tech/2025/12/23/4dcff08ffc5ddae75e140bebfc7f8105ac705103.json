{
  "id": "4dcff08ffc5ddae75e140bebfc7f8105ac705103",
  "title": "OpenAI’s child exploitation reports increased sharply this year",
  "summary": "Incident reports spiked during the first six months of 2025.",
  "canonicalUrl": "https://arstechnica.com/tech-policy/2025/12/openais-child-exploitation-reports-increased-sharply-this-year",
  "source": {
    "id": "arstechnica",
    "name": "Ars Technica",
    "url": "https://arstechnica.com/",
    "feedUrl": "https://feeds.arstechnica.com/arstechnica/index",
    "country": "US",
    "language": "en"
  },
  "publishedAt": "2025-12-23T17:02:26.000Z",
  "fetchedAt": "2025-12-24T00:05:19.483Z",
  "category": "tech",
  "tags": [
    "AI",
    "Policy",
    "ai csam",
    "csam",
    "NCMEC",
    "openai",
    "syndication"
  ],
  "image": "https://cdn.arstechnica.net/wp-content/uploads/2024/04/openai-logo-1024x648.jpg",
  "language": "en",
  "storagePath": "data/articles/tech/2025/12/23/4dcff08ffc5ddae75e140bebfc7f8105ac705103.json",
  "contentText": "OpenAI sent 80 times as many child exploitation incident reports to the National Center for Missing & Exploited Children during the first half of 2025 as it did during a similar time period in 2024, according to a recent update from the company. The NCMEC’s CyberTipline is a Congressionally authorized clearinghouse for reporting child sexual abuse material (CSAM) and other forms of child exploitation.\n\nCompanies are required by law to report apparent child exploitation to the CyberTipline. When a company sends a report, NCMEC reviews it and then forwards it to the appropriate law enforcement agency for investigation.\n\nStatistics related to NCMEC reports can be nuanced. Increased reports can sometimes indicate changes in a platform’s automated moderation, or the criteria it uses to decide whether a report is necessary, rather than necessarily indicating an increase in nefarious activity.\n\nRead full article\n\nComments",
  "contentSource": "content:encoded"
}
