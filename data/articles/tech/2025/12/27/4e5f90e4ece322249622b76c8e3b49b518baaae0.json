{
  "id": "4e5f90e4ece322249622b76c8e3b49b518baaae0",
  "title": "As inference splits into prefill and decode, Nvidia's Groq deal could enable a \"Rubin SRAM\" variant optimized for ultra-low latency agentic reasoning workloads (Gavin Baker/@gavinsbaker)",
  "summary": "Gavin Baker / @gavinsbaker: As inference splits into prefill and decode, Nvidia's Groq deal could enable a “Rubin SRAM” variant optimized for ultra-low latency agentic reasoning workloads — Nvidia is buying Groq for two reasons imo. 1) Inference is disaggregating into prefill and decode.",
  "canonicalUrl": "http://www.techmeme.com/251227/p4",
  "source": {
    "id": "techmeme",
    "name": "Techmeme",
    "url": "https://www.techmeme.com/",
    "feedUrl": "https://www.techmeme.com/feed.xml",
    "country": "US",
    "language": "en"
  },
  "publishedAt": "2025-12-27T07:35:01.000Z",
  "fetchedAt": "2025-12-27T08:29:51.519Z",
  "category": "tech",
  "tags": [],
  "image": "http://www.techmeme.com/img/pml.png",
  "language": "en",
  "storagePath": "data/articles/tech/2025/12/27/4e5f90e4ece322249622b76c8e3b49b518baaae0.json"
}
